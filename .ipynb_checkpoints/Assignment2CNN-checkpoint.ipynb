{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "The MNIST dataset consists of handwritten digit images and it is divided into 60,000 examples for the\n",
    "training set and 10,000 examples for testing. The dataset also provides images in such a way that you\n",
    "can extract labels for each image which tells you which digit does the image represent.\n",
    "Your task involves clustering these images such that all the images representing the same digit should\n",
    "belong to one cluster. You can use any method to provide the input to the clustering algorithm. Since\n",
    "1you already have the labels available, you need to also report the accuracy you have obtained while\n",
    "clustering the images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment this if running locally on Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fhZ_Rm55guqm",
    "outputId": "2ace7a7b-b3b9-4316-ca74-bbcac279e24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open drive/My Drive/1272_2280_bundle_archive.zip, drive/My Drive/1272_2280_bundle_archive.zip.zip or drive/My Drive/1272_2280_bundle_archive.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "! unzip 'drive/My Drive/1272_2280_bundle_archive.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htVAUgeth3Hf"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZm-d4U7hJZz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bbirdiiE24gS",
    "outputId": "a70f4eba-e5fb-4f1b-d767-debdbd82d440"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LmGE9dqe25R3"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vv1UXL5L2_ky"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FYrdzp9P262t",
    "outputId": "bc941b06-1483-4f98-bf04-76fb20caa8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('trainingSet/trainingSet',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIAjYa5I3X4T"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A4UBrjdR3YSs",
    "outputId": "0d2c934a-325f-4c3f-8a23-4d9aaf837abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('testSet',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLMbM_Qs4_ub"
   },
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BLmfym525CwI"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fmu_Jro5AFq"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QA7IqnmN6eqc"
   },
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Irq3v4Ft6cKO"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgSCwvyA6ysN"
   },
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMhGFWGp6x7f"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00mVJrvu65ib"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJG-Itfy63i9"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mM2dbF6m691f"
   },
   "source": [
    "### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYp9kue365-f"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EE4HZTLx7DjV"
   },
   "source": [
    "### Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtgzjhhP7Cxn"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rWzCD9zc7KpN"
   },
   "source": [
    "### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pit4ZR9J7ISQ"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQmUFNkCEXHg"
   },
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h750XjVpEhIN"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IZLZxogEchZ"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtr3cPYgFajA"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "colab_type": "code",
    "id": "5VDAeGPlEZ14",
    "outputId": "77b53ff2-b3bb-4f34-ceb5-74b0769d9378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 293/1313 [=====>........................] - ETA: 2:31 - loss: 0.5714 - accuracy: 0.8131"
     ]
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CkDjVWp_FfjS"
   },
   "source": [
    "## Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NOWHRvUcFhE4",
    "outputId": "7b8ee5c3-9bc7-4ebc-dfcb-d34183014db0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('testSet/testSet/img_1225.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 0\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 1\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 2\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 3\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 4\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 5\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 6\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 7\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 8\n",
    "elif result[0][9] == 1:\n",
    "    prediction = 9\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('3.1.png', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 0\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 1\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 2\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 3\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 4\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 5\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 6\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 7\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 8\n",
    "elif result[0][9] == 1:\n",
    "    prediction = 9\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('5.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 0\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 1\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 2\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 3\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 4\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 5\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 6\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 7\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 8\n",
    "elif result[0][9] == 1:\n",
    "    prediction = 9\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('6.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 0\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 1\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 2\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 3\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 4\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 5\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 6\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 7\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 8\n",
    "elif result[0][9] == 1:\n",
    "    prediction = 9\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "rPUxf0iOGs-a",
    "outputId": "1d663626-ab81-44de-ca94-18449ae1e69f"
   },
   "outputs": [],
   "source": [
    "lst_test = []\n",
    "import os\n",
    "for filename in os.listdir('testSet/testSet'):\n",
    "    img_path = os.path.join('testSet/testSet', filename)\n",
    "    \n",
    "    \n",
    "    test_image = image.load_img(img_path, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = cnn.predict(test_image)\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 0\n",
    "    elif result[0][1] == 1:\n",
    "        prediction = 1\n",
    "    elif result[0][2] == 1:\n",
    "        prediction = 2\n",
    "    elif result[0][3] == 1:\n",
    "        prediction = 3\n",
    "    elif result[0][4] == 1:\n",
    "        prediction = 4\n",
    "    elif result[0][5] == 1:\n",
    "        prediction = 5\n",
    "    elif result[0][6] == 1:\n",
    "        prediction = 6\n",
    "    elif result[0][7] == 1:\n",
    "        prediction = 7\n",
    "    elif result[0][8] == 1:\n",
    "        prediction = 8\n",
    "    elif result[0][9] == 1:\n",
    "        prediction = 9\n",
    "        \n",
    "    lst_test.append(prediction)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
