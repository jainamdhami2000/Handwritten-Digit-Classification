{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "The MNIST dataset consists of handwritten digit images and it is divided into 60,000 examples for the\n",
    "training set and 10,000 examples for testing. The dataset also provides images in such a way that you\n",
    "can extract labels for each image which tells you which digit does the image represent.\n",
    "Your task involves clustering these images such that all the images representing the same digit should\n",
    "belong to one cluster. You can use any method to provide the input to the clustering algorithm. Since\n",
    "1you already have the labels available, you need to also report the accuracy you have obtained while\n",
    "clustering the images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment this if running locally on Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fhZ_Rm55guqm",
    "outputId": "2ace7a7b-b3b9-4316-ca74-bbcac279e24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open drive/My Drive/1272_2280_bundle_archive.zip, drive/My Drive/1272_2280_bundle_archive.zip.zip or drive/My Drive/1272_2280_bundle_archive.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "! unzip 'drive/My Drive/1272_2280_bundle_archive.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htVAUgeth3Hf"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZm-d4U7hJZz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bbirdiiE24gS",
    "outputId": "a70f4eba-e5fb-4f1b-d767-debdbd82d440"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LmGE9dqe25R3"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vv1UXL5L2_ky"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FYrdzp9P262t",
    "outputId": "bc941b06-1483-4f98-bf04-76fb20caa8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('trainingSet/trainingSet',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIAjYa5I3X4T"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A4UBrjdR3YSs",
    "outputId": "0d2c934a-325f-4c3f-8a23-4d9aaf837abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('testSet',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLMbM_Qs4_ub"
   },
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BLmfym525CwI"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fmu_Jro5AFq"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QA7IqnmN6eqc"
   },
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Irq3v4Ft6cKO"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgSCwvyA6ysN"
   },
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMhGFWGp6x7f"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00mVJrvu65ib"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJG-Itfy63i9"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mM2dbF6m691f"
   },
   "source": [
    "### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYp9kue365-f"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EE4HZTLx7DjV"
   },
   "source": [
    "### Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtgzjhhP7Cxn"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rWzCD9zc7KpN"
   },
   "source": [
    "### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pit4ZR9J7ISQ"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQmUFNkCEXHg"
   },
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h750XjVpEhIN"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IZLZxogEchZ"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtr3cPYgFajA"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "colab_type": "code",
    "id": "5VDAeGPlEZ14",
    "outputId": "77b53ff2-b3bb-4f34-ceb5-74b0769d9378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1313/1313 [==============================] - 204s 155ms/step - loss: 0.2909 - accuracy: 0.9079 - val_loss: 104.6639 - val_accuracy: 0.0972\n",
      "Epoch 2/20\n",
      "1313/1313 [==============================] - 189s 144ms/step - loss: 0.1138 - accuracy: 0.9646 - val_loss: 123.6141 - val_accuracy: 0.0976\n",
      "Epoch 3/20\n",
      "1313/1313 [==============================] - 175s 133ms/step - loss: 0.0838 - accuracy: 0.9737 - val_loss: 127.7643 - val_accuracy: 0.0956\n",
      "Epoch 4/20\n",
      "1313/1313 [==============================] - 175s 133ms/step - loss: 0.0662 - accuracy: 0.9790 - val_loss: 145.5685 - val_accuracy: 0.1007\n",
      "Epoch 5/20\n",
      "1313/1313 [==============================] - 176s 134ms/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 150.4648 - val_accuracy: 0.0999\n",
      "Epoch 6/20\n",
      "1313/1313 [==============================] - 186s 142ms/step - loss: 0.0529 - accuracy: 0.9839 - val_loss: 148.0186 - val_accuracy: 0.0999\n",
      "Epoch 7/20\n",
      "1313/1313 [==============================] - 181s 138ms/step - loss: 0.0442 - accuracy: 0.9852 - val_loss: 167.9611 - val_accuracy: 0.0991\n",
      "Epoch 8/20\n",
      "1313/1313 [==============================] - 196s 149ms/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 177.7299 - val_accuracy: 0.0993\n",
      "Epoch 9/20\n",
      "1313/1313 [==============================] - 183s 139ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 186.7906 - val_accuracy: 0.0989\n",
      "Epoch 10/20\n",
      "1313/1313 [==============================] - 200s 153ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 176.5317 - val_accuracy: 0.1002\n",
      "Epoch 11/20\n",
      "1313/1313 [==============================] - 193s 147ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 212.3330 - val_accuracy: 0.0991\n",
      "Epoch 12/20\n",
      "1313/1313 [==============================] - 180s 137ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 201.9252 - val_accuracy: 0.0984\n",
      "Epoch 13/20\n",
      "1313/1313 [==============================] - 190s 144ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 196.1324 - val_accuracy: 0.0986\n",
      "Epoch 14/20\n",
      "1313/1313 [==============================] - 177s 135ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 196.1796 - val_accuracy: 0.0989\n",
      "Epoch 15/20\n",
      "1313/1313 [==============================] - 163s 124ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 207.3221 - val_accuracy: 0.0991\n",
      "Epoch 16/20\n",
      "1313/1313 [==============================] - 187s 142ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 211.4971 - val_accuracy: 0.0991\n",
      "Epoch 17/20\n",
      "1313/1313 [==============================] - 184s 140ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 227.8064 - val_accuracy: 0.0985\n",
      "Epoch 18/20\n",
      "1313/1313 [==============================] - 205s 156ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 219.9979 - val_accuracy: 0.0991\n",
      "Epoch 19/20\n",
      "1313/1313 [==============================] - 207s 158ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 219.4277 - val_accuracy: 0.0994\n",
      "Epoch 20/20\n",
      "1313/1313 [==============================] - 204s 155ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 206.6048 - val_accuracy: 0.0994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f113f697310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CkDjVWp_FfjS"
   },
   "source": [
    "## Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NOWHRvUcFhE4",
    "outputId": "7b8ee5c3-9bc7-4ebc-dfcb-d34183014db0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('testSet/testSet/img_1225.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 0\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 1\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 2\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 3\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 4\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 5\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 6\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 7\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 8\n",
    "elif result[0][9] == 1:\n",
    "    prediction = 9\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('3.1.png', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 0\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 1\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 2\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 3\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 4\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 5\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 6\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 7\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 8\n",
    "elif result[0][9] == 1:\n",
    "    prediction = 9\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('5.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 0\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 1\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 2\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 3\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 4\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 5\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 6\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 7\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 8\n",
    "elif result[0][9] == 1:\n",
    "    prediction = 9\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('6.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 0\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 1\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 2\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 3\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 4\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 5\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 6\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 7\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 8\n",
    "elif result[0][9] == 1:\n",
    "    prediction = 9\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "rPUxf0iOGs-a",
    "outputId": "1d663626-ab81-44de-ca94-18449ae1e69f"
   },
   "outputs": [],
   "source": [
    "lst_test = []\n",
    "import os\n",
    "for filename in os.listdir('testSet/testSet'):\n",
    "    img_path = os.path.join('testSet/testSet', filename)\n",
    "    \n",
    "    \n",
    "    test_image = image.load_img(img_path, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = cnn.predict(test_image)\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 0\n",
    "    elif result[0][1] == 1:\n",
    "        prediction = 1\n",
    "    elif result[0][2] == 1:\n",
    "        prediction = 2\n",
    "    elif result[0][3] == 1:\n",
    "        prediction = 3\n",
    "    elif result[0][4] == 1:\n",
    "        prediction = 4\n",
    "    elif result[0][5] == 1:\n",
    "        prediction = 5\n",
    "    elif result[0][6] == 1:\n",
    "        prediction = 6\n",
    "    elif result[0][7] == 1:\n",
    "        prediction = 7\n",
    "    elif result[0][8] == 1:\n",
    "        prediction = 8\n",
    "    elif result[0][9] == 1:\n",
    "        prediction = 9\n",
    "        \n",
    "    lst_test.append(prediction)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
